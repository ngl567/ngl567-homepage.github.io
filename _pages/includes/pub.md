
# 📝 Publications 
## Knowledge Graph


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DASFAA 2025</div><img src='images/dhns.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Diffusion-based Hierarchical Negative Sampling for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2501.15393) \\
**Guanglin Niu**, Xiaowei Zhang

_The 30th International Conference on Database Systems for Advanced Applications (DASFAA), 2025_

- DHNS is the first to leverage the diffusion model’s capabilities within the context of multi-modal knowledge graph for negative sampling.

📃[**Paper**](https://arxiv.org/pdf/2501.15393)     💾[**Code**](https://github.com/ngl567/DHNS) ![img](https://img.shields.io/github/stars/ngl567/DHNS?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='images/lcge.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Logic and Commonsense-Guided Temporal Knowledge Graph Completion](https://ojs.aaai.org/index.php/AAAI/article/view/25579) \\
**Guanglin Niu**, Bo Li

_Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2023_

  - This work is the first to introduce temporal rules into temporal knowledge graph completion models.
  - LCGE models each event from the perspectives of both the time-sensitive representation and the commonsense.
  - Our work is promoted by some media and forums, such as [AI Time青年科学家论坛](https://mp.weixin.qq.com/s/GP_S9U4EWJD0JGZcdJO3lg).

📃[**Paper**](https://ojs.aaai.org/index.php/AAAI/article/view/25579)     💾[**Code**](https://github.com/ngl567/LCGE) ![img](https://img.shields.io/github/stars/ngl567/LCGE?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2022</div><img src='images/cake.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion](https://aclanthology.org/2022.acl-long.205) <strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:3fE2CSJIrl8C'></span></strong> \\
**Guanglin Niu**, Bo Li, Yongfei Zhang, Shiliang Pu

_Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (ACL), 2022_

  - This work is the first to propose a scalable knowledge graph completion framework to predict entities in a joint commonsense and fact-driven fashion.
  - CAKE consists of an automatic commonsense generation mechanism, a commonsense-aware negative sampling strategy and a multi-view link prediction mechanism.
  - Our work is promoted by several media and forums, such as [AI Time 视频](https://www.bilibili.com/video/BV1Q44y1g78Z/) \| [AI Time 解读](https://mp.weixin.qq.com/s/xQ625k_2kYXerZtO6M8mGg)、[专知](https://www.zhuanzhi.ai/document/5648511d67d6e512eb3521ac47d763d4)、[智源社区](https://hub.baai.ac.cn/view/19366)、[开放知识图谱](https://mp.weixin.qq.com/s/1wVS2aJd6ddyPkvZHx3Lrw)、[AMiner](https://www.aminer.cn/research_report/627c81397cb68b460fb6063d).

📃[**Paper**](https://aclanthology.org/2022.acl-long.205.pdf)     💾[**Code**](https://github.com/ngl567/CAKE) ![img](https://img.shields.io/github/stars/ngl567/CAKE?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR 2021</div><img src='images/gana.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Relational Learning with Gated and Attentive Neighbor Aggregator for Few-Shot Knowledge Graph Completion](https://dl.acm.org/doi/10.1145/3404835.3462925) <strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:WF5omc3nYNoC'></span></strong> \\
**Guanglin Niu**, Yang Li, Chengguang Tang, Ruiying Geng, Jian Dai, Qiao Liu, Hao Wang, Jian Sun, Fei Huang, Luo Si

_Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2021_

  - This approach is the first to propose a gated and attentive neighbor aggregator to capture the most valuable contextual semantics of a relation.
  - GANA is one of the most representative models and always selected as the baseline on few-show knowledge graph completion tasks.
  - This work was conducted in collaboration with Qwen team. Our work is promoted by some media and forums, such as [专知](https://www.zhuanzhi.ai/document/01403034427fa0520e958ee1fe4afc56).

📃[**Paper**](https://arxiv.org/pdf/2104.13095)     💾[**Code**](https://github.com/ngl567/GANA-FewShotKGC) ![img](https://img.shields.io/github/stars/ngl567/GANA-FewShotKGC?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2020</div><img src='images/rpje.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Rule-Guided Compositional Representation Learning on Knowledge Graphs](https://ojs.aaai.org//index.php/AAAI/article/view/5687)
<strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:IjCSPb-OGe4C'></span></strong> \\
**Guanglin Niu**, Yongfei Zhang, Bo Li, Peng Cui, Si Liu, Jingyang Li and Xiaowei Zhang

_Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2020_

  - This work is the first attempt to integrate logic rules with paths for KG embedding, endowing our model with both the explainability from semantic level and the generalization from data level.
  - Our work is promoted by several media and forums, such as [开放知识图谱](https://mp.weixin.qq.com/s/tsXKwgbd2Z0XZcZZD2wcwQ)、[雷锋网](https://www.leiphone.com/news/201912/5yfuCAlZlbFDypnH.html)、[SAAI](https://zhuanlan.zhihu.com/p/137519588)、[MLNLP](https://www.bilibili.com/video/BV1zV4y1V7j4/). Particularly, our research was recognized as one of the representative studies in the field of neuro-symbolic knowledge graph reasoning at ([CCKS 2021](https://event-cdn.baai.ac.cn/live/20211228-01/Session4.mp4)).

📃[**Paper**](https://ojs.aaai.org//index.php/AAAI/article/view/5687)     💾[**Code**](https://github.com/ngl567/RPJE) ![img](https://img.shields.io/github/stars/ngl567/RPJE?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2020 Findings</div><img src='images/autoeter.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AutoETER: Automated Entity Type Representation with Relation-Aware Attention for Knowledge Graph Embedding](https://www.aclweb.org/anthology/2020.findings-emnlp.105/)
<strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:IjCSPb-OGe4C'></span></strong> \\
**Guanglin Niu**, Yongfei Zhang, Bo Li, Shiliang Pu and Jingyang Li

_Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings (EMNLP Findings), 2020_

  - This work is the first to automatically learn the embeddings of entity types to enrich the general features of entities without explicit type information.
  - Our work is promoted by several media and forums, such as [AI Time](https://www.bilibili.com/video/BV1Q44y1g78Z/)、[SFFAI](https://www.bilibili.com/video/av590645807/)、[专知](https://mp.weixin.qq.com/s/bU6Y42250GLmXiRzi8N1Wg).

📃[**Paper**](https://aclanthology.org/2020.findings-emnlp.105.pdf)     💾[**Code**](https://github.com/ngl567/AutoETER) ![img](https://img.shields.io/github/stars/ngl567/AutoETER?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">COLING 2022</div><img src='images/enginekg.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Perform like an Engine: A Closed-Loop Neural-Symbolic Learning Framework for Knowledge Graph Inference](https://aclanthology.org/2022.coling-1.119/)\\
**Guanglin Niu**, Bo Li, Yongfei Zhang, Shiliang Pu

_Proceedings of the 29th International Conference on Computational Linguistics (COLING), 2022_

  - We develop a novel closed-loop neural-symbolic learning framework that performs embedding-based rule learning and rule-enhanced knowledge graph embedding iteratively. Interestingly, EngineKG performs like a four-stroke engine.
  - Our work is promoted by some media and forums, such as [MLNLP Talk](https://www.bilibili.com/video/BV1zV4y1V7j4/).

📃[**Paper**](https://aclanthology.org/2022.coling-1.119.pdf)     💾[**Code**](https://github.com/ngl567/EngineKG)
</div>
</div>


- `AAAI 2024` [Emotion Rendering for Conversational Speech Synthesis with Heterogeneous Graph-Based Context Modeling](https://arxiv.org/abs/2312.11947), Rui Liu, Yifan Hu, **Yi Ren**, et al. [![](https://img.shields.io/github/stars/walker-hyf/ECSS?style=social&label=Code+Stars)](https://github.com/walker-hyf/ECSS)
- ``ICML 2023`` [Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models](https://text-to-audio.github.io/paper.pdf), Rongjie Huang, Jiawei Huang, Dongchao Yang, **Yi Ren**, et al.
- ``ICML 2019`` <span style="color:red">(Oral)</span> [Almost Unsupervised Text to Speech and Automatic Speech Recognition](https://pdfs.semanticscholar.org/9075/a3e6271e5ef4953491488d1776527e632408.pdf), **Yi Ren**, Xu Tan, Tao Qin, et al.  \| [**Project**](https://speechresearch.github.io/unsuper/) 

## 🖼️ Computer Vision

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024</div><img src='images/real3d.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis](https://openreview.net/forum?id=7ERQPyR2eb), Zhenhui Ye, Tianyun Zhong, Yi Ren, et al. <span style="color:red">(Spotlight)</span> [**Project**](https://real3dportrait.github.io/) | [**Code**](https://github.com/yerfor/Real3DPortrait)
</div>
</div>

- `ICLR 2023` [GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://openreview.net/forum?id=YfwMIDhPccD), Zhenhui Ye, Ziyue Jiang, **Yi Ren**, et al.

  
## 📚 Large Language Model
- ``ACL 2023`` [AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation](), Rongjie Huang, Huadai Liu, Xize Cheng, **Yi Ren**, et al.
- `ICLR 2023` [TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation](https://openreview.net/forum?id=UVAmFAtC5ye), Rongjie Huang, Jinglin Liu, Huadai Liu, **Yi Ren**, Lichao Zhang, Jinzheng He, Zhou Zhao
- ``AAAI 2021`` [UWSpeech: Speech to Speech Translation for Unwritten Languages](https://arxiv.org/abs/2006.07926), Chen Zhang, Xu Tan, **Yi Ren**, et al. \| [**Project**](https://speechresearch.github.io/uwspeech/)
- ``IJCAI 2020`` [Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation](https://www.ijcai.org/Proceedings/2020/0534.pdf), Jinglin Liu, **Yi Ren**, Xu Tan, et al.
- ``ACL 2020`` [SimulSpeech: End-to-End Simultaneous Speech to Text Translation](https://www.aclweb.org/anthology/2020.acl-main.350), **Yi Ren**, Jinglin Liu, Xu Tan, et al.
- ``ACL 2020`` [A Study of Non-autoregressive Model for Sequence Generation](https://arxiv.org/abs/2004.10454), **Yi Ren**, Jinglin Liu, Xu Tan, et al.
- ``ICLR 2019`` [Multilingual Neural Machine Translation with Knowledge Distillation](https://openreview.net/forum?id=S1gUsoR9YX), Xu Tan, **Yi Ren**, Di He, et al.


## Others
- ``ICLR 2022`` [Pseudo Numerical Methods for Diffusion Models on Manifolds](https://openreview.net/forum?id=PlKWVd2yBkY), Luping Liu, **Yi Ren**, Zhijie Lin, Zhou Zhao \| [![](https://img.shields.io/github/stars/luping-liu/PNDM?style=social&label=Code+Stars)](https://github.com/luping-liu/PNDM) \| [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pseudo-numerical-methods-for-diffusion-models-1/image-generation-on-celeba-64x64)](https://paperswithcode.com/sota/image-generation-on-celeba-64x64?p=pseudo-numerical-methods-for-diffusion-models-1)
